{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6c3975",
   "metadata": {},
   "source": [
    "# Fine-tune ruBERT-tiny2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c2bfd",
   "metadata": {},
   "source": [
    "Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1521b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vboxuser/dev/bertnews/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from transformers import AutoModel, AutoTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, Dataset\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90537de",
   "metadata": {},
   "source": [
    "Загружаем отобранные статьи "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c463b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datanews.json', encoding=\"utf-8\") as f:\n",
    "    read_data = f.read()\n",
    "read_data = read_data.replace('\\n][\\n', ',\\n')\n",
    "articles = pd.read_json(StringIO(read_data), orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d7978",
   "metadata": {},
   "source": [
    "Формируем предложения из статей. Второе предложение типа \"МОСКВА, 12 янв – РИА Новости\" убираем.\n",
    "В новый DataFrame записываем предложени и их длину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06011b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В Госдуме предложили сделать старый Новый год ...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Председатель союза дачников Подмосковья и депу...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"После длинных новогодних праздников людям тяж...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  len\n",
       "0  В Госдуме предложили сделать старый Новый год ...   84\n",
       "1  Председатель союза дачников Подмосковья и депу...  234\n",
       "2  \"После длинных новогодних праздников людям тяж...  176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst = nltk.PunktSentenceTokenizer()\n",
    "sentences = pd.DataFrame({\"sentence\": [], \"len\": []})\n",
    "for ind in articles.index:\n",
    "    sentArticle = pst.tokenize(articles['Article'][ind])\n",
    "    m = 0\n",
    "    for s in sentArticle:\n",
    "        if m != 1:\n",
    "            sentences.loc[len(sentences.index)] = [s, len(s)]\n",
    "print(\"Number of sentences: \", len(sentences.index))\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaeef6e",
   "metadata": {},
   "source": [
    "Формируем набор для обучения и тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17621ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "train_text = train['sentence'].astype('str')\n",
    "test_text = test['sentence'].astype('str')\n",
    "train_labels = train.index\n",
    "test_labels = test.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2dc5d",
   "metadata": {},
   "source": [
    "Задание всех seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d39490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce62456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ad7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.values.tolist(),\n",
    "    padding = True,\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.values.tolist(),\n",
    "    padding = True,\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93136651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = Data(tokens_train, train_labels)\n",
    "test_dataset = Data(tokens_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba9a24",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/accuracy_score-in-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40141fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(Y_true, Y_pred):  \n",
    "    correctly_predicted = 0  \n",
    "    # iterating over every label and checking it with the true sample  \n",
    "    for true_label, predicted in zip(Y_true, Y_pred):  \n",
    "        if true_label == predicted:  \n",
    "            correctly_predicted += 1  \n",
    "    # computing the accuracy score  \n",
    "    accuracy_score = correctly_predicted / len(Y_true)  \n",
    "    return accuracy_score  \n",
    "\n",
    "# Training the model using the Support Vector Classification class of sklearn  \n",
    "svc = SVC()  \n",
    "svc.fit(tokens_train['input_ids'], train_labels)  \n",
    "  \n",
    "# Computing the accuracy score of the model  \n",
    "Y_pred = svc.predict(tokens_train['input_ids'])  \n",
    "score = compute_accuracy(test_labels, Y_pred)  \n",
    "print(score)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertnews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
