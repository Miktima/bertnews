{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6c3975",
   "metadata": {},
   "source": [
    "# Fine-tune masked ruBERT-tiny2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c2bfd",
   "metadata": {},
   "source": [
    "Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1521b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer, AutoModel\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90537de",
   "metadata": {},
   "source": [
    "Загружаем отобранные предложения. Предложения отбираются в скрипте precorrect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c463b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>В Саратове при пожаре погиб мужчина, спасшийся...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Лаврентьев: США приказали оппозиции в Сирии на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Лаврентьев рассказал о контактах спецслужб Рос...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>В Ростове-на-Дону арестовали двух украинских а...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Посол США обвинил Орбана в пророссийской внешн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1042  В Саратове при пожаре погиб мужчина, спасшийся...      1\n",
       "1043  Лаврентьев: США приказали оппозиции в Сирии на...      1\n",
       "1044  Лаврентьев рассказал о контактах спецслужб Рос...      1\n",
       "1045  В Ростове-на-Дону арестовали двух украинских а...      1\n",
       "1046  Посол США обвинил Орбана в пророссийской внешн...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('CorrectDN.json', encoding=\"utf-8\") as f:\n",
    "    sentences = pd.read_json(f, orient='records')\n",
    "sentences.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17621ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530c7899fb9847e08fd106f306bc9adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/1047 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c63e964f09f4bf29dce07a411e07390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1047 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['1'], id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds = Dataset.from_pandas(sentences, preserve_index=False)\n",
    "raw_ds = raw_ds.class_encode_column('label')\n",
    "raw_ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a6def",
   "metadata": {},
   "source": [
    "Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6522d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = raw_ds.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce62456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model_checkpoint = \"cointegrated/rubert-tiny2\"\n",
    "# model_checkpoint = \"DeepPavlov/rubert-base-cased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683579bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85610d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"После начала российской военной [MASK] на Украине западные страны усилили санкционное давление на Москву\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4354efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61407\n",
      "tensor(4.6802e-07, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7577e-05, grad_fn=<SelectBackward0>)\n",
      "tensor(7.1256e-07, grad_fn=<SelectBackward0>)\n",
      "'>>> службы (10969)  >>>>: 0.10826659202575684\n",
      "'>>> операции (11394)  >>>>: 0.07997777312994003\n",
      "'>>> политики (17480)  >>>>: 0.07752140611410141\n",
      "'>>> силы (11885)  >>>>: 0.06181306019425392\n",
      "'>>> кампании (22938)  >>>>: 0.046161551028490067\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits = model(**inputs).logits\n",
    "#print (inputs)\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "# print (mask_token_index)\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "word = \"спецоперации\"\n",
    "iii = tokenizer(word, return_tensors=\"pt\")\n",
    "moscow_token = iii[\"input_ids\"][0][1].item()\n",
    "print (moscow_token)\n",
    "\n",
    "probs = torch.nn.functional.softmax(mask_token_logits, dim=1)\n",
    "print (probs[0][29571])\n",
    "print (probs[0][19534])\n",
    "print (probs[0][moscow_token])\n",
    "\n",
    "top_5_prob = torch.topk(probs, 5, dim=1)\n",
    "val = top_5_prob.values[0].tolist()\n",
    "ind = top_5_prob.indices[0].tolist()\n",
    "for i in range(len(val)):\n",
    "    print (f\"'>>> {tokenizer.decode([ind[i]])} ({ind[i]})  >>>>: {val[i]}\")\n",
    "print (\"-----------------\")\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(val_all)):\n",
    "#     if ind[i] == 17627:\n",
    "#         print (f\"'>>> {tokenizer.decode([ind_all[i]])}  >>>>: {val_all[i]}\")\n",
    "\n",
    "#for token in top_5_tokens:\n",
    "#    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}' {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eeccb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8c2af92ee24eb3b6b0484f4371ad1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fff9d05ab24df7b41d589aa02ae5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 553\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 139\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = raw_ds.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a1e1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38967e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f4c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 59'\n",
      "'>>> Review 1 length: 481'\n",
      "'>>> Review 2 length: 158'\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59dc4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 698'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d61751c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 58'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f39cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dfb752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9d12d785fd4fe58edcd5ffd7111011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c108fdf0203a4694aa86471c7e8c7914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 1001\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "005310be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ХАЛ ). Военные добавили, что на месте происшествия были обнаружены винтовка, топор и боеприпасы. Израиль 7 октября подвергся беспрецедентной по масштабу ракетной атаке из сектора Газа в рамках объявленной военным крылом палестинского движения ХАМАС операции \" Потоп Аль - Аксы \". После этого бойцы организации проникли в приграничные районы на юге Израиля, где открывали огонь как по военным, так и по гражданским, а также взяли более 200 заложников. В Израиле, по последним данным властей, погибли около 1, 2 тысячи человек, это число включает гражданских лиц, солдат, иностранных граждан и рабочих, также сообщалось, что пострадали более 5 тысяч. В ответ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2293f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8b7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b0cadfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] [MASK]ин рассказал о росте раскрытых дел об экстремизме председатель СК [MASK] Александр Бастрыкин Ансам \" Что касается экстремизма, то мы направили в суд 430 уголовных дел, что на 62 % больше, чем в прошлом году \", - сказал глава ведомства. [MASK] полный текст интервью > > > [SEP] [CLS] [MASK] ЦАХАЛ застрелили палестин [MASK] на блокпосту на Западном берегу ТЕЛЬ - [MASK]ИВ [MASK] 14 янв [MASK] [MASK] [MASK]. Израильские [MASK] в воскресенье застрелили палестинцев, которые на [MASK] прорвались [MASK] один из блокпостов на [MASK] [MASK] и во [MASK] погони стреляли по солдатам, [MASK] пресс - служба Армии обороны Израиля ( ЦА'\n",
      "\n",
      "'>>> ##ХАЛ [MASK]. Военные добавили, что на месте [MASK] были обнаружены винтов [MASK], [MASK] и боеприпасы [MASK] Израиль 7 октября подвергся беспрецедент [MASK] по масштабу ракетной атаке из сектора Газа в рамках объявленной военным крылом палестинского движения ХАМАС операции [MASK] Потоп [MASK] - [MASK]сы [MASK]. После этого бойцы организации [MASK] в приграничные районы на [MASK] [MASK], где открывали огонь [MASK] [MASK] военным [MASK] так и по гражданским [MASK] а также взяли более 200 заложников. В Израиле, по последним [MASK] властей, погибли около 1, 2 тысячи человек [MASK] это число [MASK] гражданских лиц, [MASK], иностранных граждан и [MASK], также сообщалось [MASK] что пострадали болеещик тысяч. В ответ'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae17face",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e69831df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] Бастрыкин рассказал о росте раскрытых дел об экстремизме председатель СК РФ Александр Бастрыкин. [MASK] Что касается экстремизма, то [MASK] направили в [MASK] [MASK] уголовных дел, что на [MASK] % больше, [MASK] в прошлом году \", - сказал [MASK] ведомства. [MASK] полный текст интервью > > > [SEP] [CLS] Военные ЦАХАЛ застрелили палестинцев на блокпосту на Западном берегу [MASK] [MASK] [MASK] АВИВ, 14 янв - РИА Новости. [MASK] [MASK] [MASK] в [MASK] застрелили палестинцев, [MASK] [MASK] автомобиле прорвались через один из блокпостов на Западном берегу и во время погони стреляли по солдатам, [MASK] пресс - служба Армии обороны Израиля ( ЦА'\n",
      "\n",
      "'>>> ##ХАЛ ). Военные добавили, [MASK] на месте происшествия были [MASK] винтовка [MASK] топор и [MASK] [MASK] Израиль [MASK] октября подвергся беспрецедентной по масштабу ракетной [MASK] из сектора Газа в рамках объявленной военным крылом палестинского движения ХАМАС операции \" Потоп Аль [MASK] Аксы [MASK]. После этого бойцы организации проникли в приграничные районы на юге Израиля, [MASK] открывали огонь [MASK] по военным [MASK] так и по гражданским [MASK] а также взяли более [MASK] [MASK]. [MASK] Израиле, по последним данным властей [MASK] погибли около [MASK] [MASK] 2 тысячи человек, [MASK] число включает гражданских лиц [MASK] [MASK] [MASK] иностранных граждан и [MASK], также сообщалось [MASK] что пострадали более 5 тысяч. В ответ'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc596634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    # push_to_hub=True,\n",
    "    # fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "749589e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05533dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee3ecaa3e845fe9251281b1f802ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:24<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 30.19\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertnews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
